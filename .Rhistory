pReward = getPreward(1, quitAfter, gammaPerStep)
Qquit =  pReward * tokenValue * rewardedDiscount / (1 - discount)
# Qquit =  sum(pReward * tokenValue * meanRewardDiscount * meanWaitDiscount ^ (0 : 10))
Qquit_[quitGap] = Qquit
Qwait = vector(length = quitGap)
for(j in 1 : quitGap){
meanRewardDelay = getMeanRewardDelay(j, quitAfter, gammaPerStep)
meanWaitDelay = getMeanWaitDelay(j, quitAfter, gammaPerStep)
rewardedDiscount = meanRewardDelay$discount
discount = meanWaitDelay$discount
pReward = getPreward(j, quitAfter, gammaPerStep)
Qwait[j] = tokenValue * rewardedDiscount * pReward + Qquit * discount
}
Qwait_[[quitGap]] = Qwait
}
nQuitGap = 1
Rt = vector(length = length(trialGapValues$HP))
for(lastWaitGap in 1 : nGap){
# define the transition matrix
trans = matrix(rep(0, length = (lastWaitGap + nQuitGap)^2), nrow = lastWaitGap + nQuitGap)
if(lastWaitGap > 1) trans[1 : (lastWaitGap - 1), lastWaitGap + 1]  =
unlist(lapply(1:(lastWaitGap-1), function(i) rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])))
trans[lastWaitGap, lastWaitGap + 1] = 1
if(lastWaitGap > 1) for(i in 1 : (lastWaitGap - 1)) trans[i, i+1] = 1 - trans[i, lastWaitGap + 1]
if(nQuitGap > 1) for(i in (lastWaitGap+1) : (lastWaitGap + nQuitGap-1)) trans[i, i + 1] = 1
trans[lastWaitGap + nQuitGap, 1] = 1
# calculate the steady state
n = ncol(trans)
A = t(trans - diag(n))
A = rbind(A, rep(1, n))
b = c(rep(0, n), 1)
UHP = qr.solve(A, b)
rHP = c(unlist(lapply(1 : lastWaitGap, function(i) {
rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i: nGap])
})), rep(0, nQuitGap))
timeInGaps = c(unlist(lapply(1 : lastWaitGap, function(i) {
junk = rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])
junk * stepDuration / 2 + (1 - junk) * stepDuration
})), rep(iti, nQuitGap))
rHP = rHP / timeInGaps # probability that you get reward every seconds
meanTimePerAction = sum(UHP * timeInGaps)
Rt[lastWaitGap] = sum(UHP * rHP * 10) / meanTimePerAction
}
plot(Rt / rewardRate$HP)
nQuitGap = 1
Rt = vector(length = length(trialGapValues$HP))
for(lastWaitGap in 1 : nGap){
# define the transition matrix
trans = matrix(rep(0, length = (lastWaitGap + nQuitGap)^2), nrow = lastWaitGap + nQuitGap)
if(lastWaitGap > 1) trans[1 : (lastWaitGap - 1), lastWaitGap + 1]  =
unlist(lapply(1:(lastWaitGap-1), function(i) rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])))
trans[lastWaitGap, lastWaitGap + 1] = 1
if(lastWaitGap > 1) for(i in 1 : (lastWaitGap - 1)) trans[i, i+1] = 1 - trans[i, lastWaitGap + 1]
if(nQuitGap > 1) for(i in (lastWaitGap+1) : (lastWaitGap + nQuitGap-1)) trans[i, i + 1] = 1
trans[lastWaitGap + nQuitGap, 1] = 1
# calculate the steady state
n = ncol(trans)
A = t(trans - diag(n))
A = rbind(A, rep(1, n))
b = c(rep(0, n), 1)
UHP = qr.solve(A, b)
rHP = c(unlist(lapply(1 : lastWaitGap, function(i) {
rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i: nGap])
})), rep(0, nQuitGap))
timeInGaps = c(unlist(lapply(1 : lastWaitGap, function(i) {
junk = rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])
junk * stepDuration + (1 - junk) * stepDuration
})), rep(iti, nQuitGap))
rHP = rHP / timeInGaps # probability that you get reward every seconds
meanTimePerAction = sum(UHP * timeInGaps)
Rt[lastWaitGap] = sum(UHP * rHP * 10) / meanTimePerAction
}
plot(Rt / rewardRate$HP)
meanTimePerAction
sum(UHP * timeInGaps)
c(unlist(lapply(1 : lastWaitGap, function(i) {
junk = rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])
junk * stepDuration + (1 - junk) * stepDuration
})), rep(iti, nQuitGap))
nQuitGap = 1
Rt = vector(length = length(trialGapValues$HP))
Rstep= vector(length = length(trialGapValues$HP))
for(lastWaitGap in 1 : nGap){
# define the transition matrix
trans = matrix(rep(0, length = (lastWaitGap + nQuitGap)^2), nrow = lastWaitGap + nQuitGap)
if(lastWaitGap > 1) trans[1 : (lastWaitGap - 1), lastWaitGap + 1]  =
unlist(lapply(1:(lastWaitGap-1), function(i) rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])))
trans[lastWaitGap, lastWaitGap + 1] = 1
if(lastWaitGap > 1) for(i in 1 : (lastWaitGap - 1)) trans[i, i+1] = 1 - trans[i, lastWaitGap + 1]
if(nQuitGap > 1) for(i in (lastWaitGap+1) : (lastWaitGap + nQuitGap-1)) trans[i, i + 1] = 1
trans[lastWaitGap + nQuitGap, 1] = 1
# calculate the steady state
n = ncol(trans)
A = t(trans - diag(n))
A = rbind(A, rep(1, n))
b = c(rep(0, n), 1)
UHP = qr.solve(A, b)
rHP = c(unlist(lapply(1 : lastWaitGap, function(i) {
rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i: nGap])
})), rep(0, nQuitGap))
timeInGaps = c(unlist(lapply(1 : lastWaitGap, function(i) {
junk = rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])
junk * stepDuration + (1 - junk) * stepDuration
})), rep(iti, nQuitGap))
rHP = rHP / timeInGaps # probability that you get reward every seconds
meanTimePerAction = sum(UHP * timeInGaps)
Rt[lastWaitGap] = sum(UHP * rHP * 10) / meanTimePerAction
Rstep[lastWaitGap] = sum(UHP * rHP * 10)
}
plot(Rt / rewardRate$HP)
meanTimePerAction
Rstep
nQuitGap = 20
Rt = vector(length = length(trialGapValues$HP))
Rstep= vector(length = length(trialGapValues$HP))
for(lastWaitGap in 1 : nGap){
# define the transition matrix
trans = matrix(rep(0, length = (lastWaitGap + nQuitGap)^2), nrow = lastWaitGap + nQuitGap)
if(lastWaitGap > 1) trans[1 : (lastWaitGap - 1), lastWaitGap + 1]  =
unlist(lapply(1:(lastWaitGap-1), function(i) rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])))
trans[lastWaitGap, lastWaitGap + 1] = 1
if(lastWaitGap > 1) for(i in 1 : (lastWaitGap - 1)) trans[i, i+1] = 1 - trans[i, lastWaitGap + 1]
if(nQuitGap > 1) for(i in (lastWaitGap+1) : (lastWaitGap + nQuitGap-1)) trans[i, i + 1] = 1
trans[lastWaitGap + nQuitGap, 1] = 1
# calculate the steady state
n = ncol(trans)
A = t(trans - diag(n))
A = rbind(A, rep(1, n))
b = c(rep(0, n), 1)
UHP = qr.solve(A, b)
rHP = c(unlist(lapply(1 : lastWaitGap, function(i) {
rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i: nGap])
})), rep(0, nQuitGap))
timeInGaps = c(unlist(lapply(1 : lastWaitGap, function(i) {
junk = rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])
junk * stepDuration + (1 - junk) * stepDuration
})), rep(iti, nQuitGap))
rHP = rHP / timeInGaps # probability that you get reward every seconds
meanTimePerAction = sum(UHP * timeInGaps)
Rt[lastWaitGap] = sum(UHP * rHP * 10) / meanTimePerAction
Rstep[lastWaitGap] = sum(UHP * rHP * 10)
}
plot(Rt / rewardRate$HP)
nQuitGap = 20
Rt = vector(length = length(trialGapValues$HP))
Rstep= vector(length = length(trialGapValues$HP))
for(lastWaitGap in 1 : nGap){
# define the transition matrix
trans = matrix(rep(0, length = (lastWaitGap + nQuitGap)^2), nrow = lastWaitGap + nQuitGap)
if(lastWaitGap > 1) trans[1 : (lastWaitGap - 1), lastWaitGap + 1]  =
unlist(lapply(1:(lastWaitGap-1), function(i) rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])))
trans[lastWaitGap, lastWaitGap + 1] = 1
if(lastWaitGap > 1) for(i in 1 : (lastWaitGap - 1)) trans[i, i+1] = 1 - trans[i, lastWaitGap + 1]
if(nQuitGap > 1) for(i in (lastWaitGap+1) : (lastWaitGap + nQuitGap-1)) trans[i, i + 1] = 1
trans[lastWaitGap + nQuitGap, 1] = 1
# calculate the steady state
n = ncol(trans)
A = t(trans - diag(n))
A = rbind(A, rep(1, n))
b = c(rep(0, n), 1)
UHP = qr.solve(A, b)
rHP = c(unlist(lapply(1 : lastWaitGap, function(i) {
rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i: nGap])
})), rep(0, nQuitGap))
timeInGaps = c(unlist(lapply(1 : lastWaitGap, function(i) {
junk = rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])
junk * stepDuration + (1 - junk) * stepDuration
})), rep(iti / nQuitGap, nQuitGap))
rHP = rHP / timeInGaps # probability that you get reward every seconds
meanTimePerAction = sum(UHP * timeInGaps)
Rt[lastWaitGap] = sum(UHP * rHP * 10) / meanTimePerAction
Rstep[lastWaitGap] = sum(UHP * rHP * 10)
}
plot(Rt / rewardRate$HP)
iti / nQuitGap
iti
nQuitGap
nQuitGap = 20
Rt = vector(length = length(trialGapValues$HP))
Rstep= vector(length = length(trialGapValues$HP))
for(lastWaitGap in 1 : nGap){
# define the transition matrix
trans = matrix(rep(0, length = (lastWaitGap + nQuitGap)^2), nrow = lastWaitGap + nQuitGap)
if(lastWaitGap > 1) trans[1 : (lastWaitGap - 1), lastWaitGap + 1]  =
unlist(lapply(1:(lastWaitGap-1), function(i) rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])))
trans[lastWaitGap, lastWaitGap + 1] = 1
if(lastWaitGap > 1) for(i in 1 : (lastWaitGap - 1)) trans[i, i+1] = 1 - trans[i, lastWaitGap + 1]
if(nQuitGap > 1) for(i in (lastWaitGap+1) : (lastWaitGap + nQuitGap-1)) trans[i, i + 1] = 1
trans[lastWaitGap + nQuitGap, 1] = 1
# calculate the steady state
n = ncol(trans)
A = t(trans - diag(n))
A = rbind(A, rep(1, n))
b = c(rep(0, n), 1)
UHP = qr.solve(A, b)
rHP = c(unlist(lapply(1 : lastWaitGap, function(i) {
rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i: nGap])
})), rep(0, nQuitGap))
timeInGaps = c(unlist(lapply(1 : lastWaitGap, function(i) {
junk = rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])
junk * stepDuration + (1 - junk) * stepDuration
})), rep(iti / nQuitGap, nQuitGap))
rHP = rHP / timeInGaps # probability that you get reward every seconds
meanTimePerAction = sum(UHP * timeInGaps)
Rt[lastWaitGap] = sum(UHP * rHP * 10) / meanTimePerAction
Rstep[lastWaitGap] = sum(UHP * rHP * 10)
}
plot(Rt / rewardRate$HP)
Rt
meanTimePerAction
timeInGaps
nQuitGap = 20
Rt = vector(length = length(trialGapValues$HP))
Rstep= vector(length = length(trialGapValues$HP))
trans = matrix(rep(0, length = (lastWaitGap + nQuitGap)^2), nrow = lastWaitGap + nQuitGap)
if(lastWaitGap > 1) trans[1 : (lastWaitGap - 1), lastWaitGap + 1]  =
unlist(lapply(1:(lastWaitGap-1), function(i) rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])))
trans[lastWaitGap, lastWaitGap + 1] = 1
if(lastWaitGap > 1) for(i in 1 : (lastWaitGap - 1)) trans[i, i+1] = 1 - trans[i, lastWaitGap + 1]
if(nQuitGap > 1) for(i in (lastWaitGap+1) : (lastWaitGap + nQuitGap-1)) trans[i, i + 1] = 1
trans[lastWaitGap + nQuitGap, 1] = 1
trans[1:20, 1:20]
trans[,1]
trans[lastWaitGap, lastWaitGap + 1]
trans[lastWaitGap+1, ]
trans[lastWaitGap+1, lastWaitGap + 2]
nQuitGap = 20
Rt = vector(length = length(trialGapValues$HP))
Rstep= vector(length = length(trialGapValues$HP))
for(lastWaitGap in 1 : nGap){
# define the transition matrix
trans = matrix(rep(0, length = (lastWaitGap + nQuitGap)^2), nrow = lastWaitGap + nQuitGap)
if(lastWaitGap > 1) trans[1 : (lastWaitGap - 1), lastWaitGap + 1]  =
unlist(lapply(1:(lastWaitGap-1), function(i) rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])))
trans[lastWaitGap, lastWaitGap + 1] = 1
if(lastWaitGap > 1) for(i in 1 : (lastWaitGap - 1)) trans[i, i+1] = 1 - trans[i, lastWaitGap + 1]
if(nQuitGap > 1) for(i in (lastWaitGap+1) : (lastWaitGap + nQuitGap-1)) trans[i, i + 1] = 1
trans[lastWaitGap + nQuitGap, 1] = 1
# calculate the steady state
n = ncol(trans)
A = t(trans - diag(n))
A = rbind(A, rep(1, n))
b = c(rep(0, n), 1)
UHP = qr.solve(A, b)
rHP = c(unlist(lapply(1 : lastWaitGap, function(i) {
rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i: nGap])
})), rep(0, nQuitGap))
timeInGaps = c(unlist(lapply(1 : lastWaitGap, function(i) {
junk = rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])
junk * stepDuration + (1 - junk) * stepDuration
})), rep(iti / nQuitGap, nQuitGap))
rHP = rHP / timeInGaps # probability that you get reward every seconds
meanTimePerAction = sum(UHP * timeInGaps)
Rt[lastWaitGap] = sum(UHP * rHP * 10) / meanTimePerAction
Rstep[lastWaitGap] = sum(UHP * rHP * 10)
}
Rt
nQuitGap = 1
Rt = vector(length = length(trialGapValues$HP))
Rstep= vector(length = length(trialGapValues$HP))
for(lastWaitGap in 1 : nGap){
# define the transition matrix
trans = matrix(rep(0, length = (lastWaitGap + nQuitGap)^2), nrow = lastWaitGap + nQuitGap)
if(lastWaitGap > 1) trans[1 : (lastWaitGap - 1), lastWaitGap + 1]  =
unlist(lapply(1:(lastWaitGap-1), function(i) rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])))
trans[lastWaitGap, lastWaitGap + 1] = 1
if(lastWaitGap > 1) for(i in 1 : (lastWaitGap - 1)) trans[i, i+1] = 1 - trans[i, lastWaitGap + 1]
if(nQuitGap > 1) for(i in (lastWaitGap+1) : (lastWaitGap + nQuitGap-1)) trans[i, i + 1] = 1
trans[lastWaitGap + nQuitGap, 1] = 1
# calculate the steady state
n = ncol(trans)
A = t(trans - diag(n))
A = rbind(A, rep(1, n))
b = c(rep(0, n), 1)
UHP = qr.solve(A, b)
rHP = c(unlist(lapply(1 : lastWaitGap, function(i) {
rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i: nGap])
})), rep(0, nQuitGap))
timeInGaps = c(unlist(lapply(1 : lastWaitGap, function(i) {
junk = rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])
junk * stepDuration + (1 - junk) * stepDuration
})), rep(iti / nQuitGap, nQuitGap))
rHP = rHP / timeInGaps # probability that you get reward every seconds
meanTimePerAction = sum(UHP * timeInGaps)
Rt[lastWaitGap] = sum(UHP * rHP * 10) / meanTimePerAction
Rstep[lastWaitGap] = sum(UHP * rHP * 10)
}
plot(Rt / rewardRate$HP)
Rt
nQuitGap = 20
Rt = vector(length = length(trialGapValues$HP))
Rstep= vector(length = length(trialGapValues$HP))
for(lastWaitGap in 1 : nGap){
# define the transition matrix
trans = matrix(rep(0, length = (lastWaitGap + nQuitGap)^2), nrow = lastWaitGap + nQuitGap)
if(lastWaitGap > 1) trans[1 : (lastWaitGap - 1), lastWaitGap + 1]  =
unlist(lapply(1:(lastWaitGap-1), function(i) rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])))
trans[lastWaitGap, lastWaitGap + 1] = 1
if(lastWaitGap > 1) for(i in 1 : (lastWaitGap - 1)) trans[i, i+1] = 1 - trans[i, lastWaitGap + 1]
if(nQuitGap > 1) for(i in (lastWaitGap+1) : (lastWaitGap + nQuitGap-1)) trans[i, i + 1] = 1
trans[lastWaitGap + nQuitGap, 1] = 1
# calculate the steady state
n = ncol(trans)
A = t(trans - diag(n))
A = rbind(A, rep(1, n))
b = c(rep(0, n), 1)
UHP = qr.solve(A, b)
rHP = c(unlist(lapply(1 : lastWaitGap, function(i) {
rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i: nGap])
})), rep(0, nQuitGap))
timeInGaps = c(unlist(lapply(1 : lastWaitGap, function(i) {
junk = rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])
junk * stepDuration + (1 - junk) * stepDuration
})), rep(iti / nQuitGap, nQuitGap))
rHP = rHP / timeInGaps # probability that you get reward every seconds
meanTimePerAction = sum(UHP * timeInGaps)
Rt[lastWaitGap] = sum(UHP * rHP * 10) / meanTimePerAction
Rstep[lastWaitGap] = sum(UHP * rHP * 10)
}
plot(Rt / rewardRate$HP)
nQuitGap = 20
Rt = vector(length = length(trialGapValues$HP))
Rstep= vector(length = length(trialGapValues$HP))
for(lastWaitGap in 1 : nGap){
# define the transition matrix
trans = matrix(rep(0, length = (lastWaitGap + nQuitGap)^2), nrow = lastWaitGap + nQuitGap)
if(lastWaitGap > 1) trans[1 : (lastWaitGap - 1), lastWaitGap + 1]  =
unlist(lapply(1:(lastWaitGap-1), function(i) rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])))
trans[lastWaitGap, lastWaitGap + 1] = 1
if(lastWaitGap > 1) for(i in 1 : (lastWaitGap - 1)) trans[i, i+1] = 1 - trans[i, lastWaitGap + 1]
if(nQuitGap > 1) for(i in (lastWaitGap+1) : (lastWaitGap + nQuitGap-1)) trans[i, i + 1] = 1
trans[lastWaitGap + nQuitGap, 1] = 1
# calculate the steady state
n = ncol(trans)
A = t(trans - diag(n))
A = rbind(A, rep(1, n))
b = c(rep(0, n), 1)
UHP = qr.solve(A, b)
rHP = c(unlist(lapply(1 : lastWaitGap, function(i) {
rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i: nGap])
})), rep(0, nQuitGap))
timeInGaps = c(unlist(lapply(1 : lastWaitGap, function(i) {
junk = rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])
junk * stepDuration + (1 - junk) * stepDuration
})), rep(iti / nQuitGap, nQuitGap))
rHP = rHP / timeInGaps # probability that you get reward every seconds
meanTimePerAction = sum(UHP * timeInGaps)
Rt[lastWaitGap] = sum(UHP * rHP * 10) / meanTimePerAction
Rstep[lastWaitGap] = sum(UHP * rHP * 10)
}
Rt20 = Rt
plot(Rt / rewardRate$HP)
nQuitGap = 1
Rt = vector(length = length(trialGapValues$HP))
Rstep= vector(length = length(trialGapValues$HP))
for(lastWaitGap in 1 : nGap){
# define the transition matrix
trans = matrix(rep(0, length = (lastWaitGap + nQuitGap)^2), nrow = lastWaitGap + nQuitGap)
if(lastWaitGap > 1) trans[1 : (lastWaitGap - 1), lastWaitGap + 1]  =
unlist(lapply(1:(lastWaitGap-1), function(i) rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])))
trans[lastWaitGap, lastWaitGap + 1] = 1
if(lastWaitGap > 1) for(i in 1 : (lastWaitGap - 1)) trans[i, i+1] = 1 - trans[i, lastWaitGap + 1]
if(nQuitGap > 1) for(i in (lastWaitGap+1) : (lastWaitGap + nQuitGap-1)) trans[i, i + 1] = 1
trans[lastWaitGap + nQuitGap, 1] = 1
# calculate the steady state
n = ncol(trans)
A = t(trans - diag(n))
A = rbind(A, rep(1, n))
b = c(rep(0, n), 1)
UHP = qr.solve(A, b)
rHP = c(unlist(lapply(1 : lastWaitGap, function(i) {
rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i: nGap])
})), rep(0, nQuitGap))
timeInGaps = c(unlist(lapply(1 : lastWaitGap, function(i) {
junk = rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])
junk * stepDuration + (1 - junk) * stepDuration
})), rep(iti / nQuitGap, nQuitGap))
rHP = rHP / timeInGaps # probability that you get reward every seconds
meanTimePerAction = sum(UHP * timeInGaps)
Rt[lastWaitGap] = sum(UHP * rHP * 10) / meanTimePerAction
Rstep[lastWaitGap] = sum(UHP * rHP * 10)
}
data.frame(Rt, Rt20)
plot(Rt20 / rewardRate$HP)
Rt20 / rewardRate$HP
Rt20
meanTimePerAction
sum(UHP * rHP * 10) / meanTimePerAction
sum(UHP * rHP * 10)
c(unlist(lapply(1 : lastWaitGap, function(i) {
junk = rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])
junk * stepDuration + (1 - junk) * stepDuration
})), rep(iti / nQuitGap, nQuitGap))
sum(UHP * timeInGaps)
sum(UHP * rHP * 10)
c(unlist(lapply(1 : lastWaitGap, function(i) {
rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i: nGap])
})), rep(0, nQuitGap))
nQuitGap = 1
Rt = vector(length = length(trialGapValues$HP))
Rstep= vector(length = length(trialGapValues$HP))
for(lastWaitGap in 1 : nGap){
# define the transition matrix
trans = matrix(rep(0, length = (lastWaitGap + nQuitGap)^2), nrow = lastWaitGap + nQuitGap)
if(lastWaitGap > 1) trans[1 : (lastWaitGap - 1), lastWaitGap + 1]  =
unlist(lapply(1:(lastWaitGap-1), function(i) rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])))
trans[lastWaitGap, lastWaitGap + 1] = 1
if(lastWaitGap > 1) for(i in 1 : (lastWaitGap - 1)) trans[i, i+1] = 1 - trans[i, lastWaitGap + 1]
if(nQuitGap > 1) for(i in (lastWaitGap+1) : (lastWaitGap + nQuitGap-1)) trans[i, i + 1] = 1
trans[lastWaitGap + nQuitGap, 1] = 1
# calculate the steady state
n = ncol(trans)
A = t(trans - diag(n))
A = rbind(A, rep(1, n))
b = c(rep(0, n), 1)
UHP = qr.solve(A, b)
rHP = c(unlist(lapply(1 : lastWaitGap, function(i) {
rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i: nGap])
})), rep(0, nQuitGap))
timeInGaps = c(unlist(lapply(1 : lastWaitGap, function(i) {
junk = rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])
junk * stepDuration + (1 - junk) * stepDuration
})), rep(iti / nQuitGap, nQuitGap))
meanTimePerAction = sum(UHP * timeInGaps)
Rt[lastWaitGap] = sum(UHP * rHP * 10) / meanTimePerAction
Rstep[lastWaitGap] = sum(UHP * rHP * 10)
}
nQuitGap = 20
Rt = vector(length = length(trialGapValues$HP))
Rstep= vector(length = length(trialGapValues$HP))
for(lastWaitGap in 1 : nGap){
# define the transition matrix
trans = matrix(rep(0, length = (lastWaitGap + nQuitGap)^2), nrow = lastWaitGap + nQuitGap)
if(lastWaitGap > 1) trans[1 : (lastWaitGap - 1), lastWaitGap + 1]  =
unlist(lapply(1:(lastWaitGap-1), function(i) rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])))
trans[lastWaitGap, lastWaitGap + 1] = 1
if(lastWaitGap > 1) for(i in 1 : (lastWaitGap - 1)) trans[i, i+1] = 1 - trans[i, lastWaitGap + 1]
if(nQuitGap > 1) for(i in (lastWaitGap+1) : (lastWaitGap + nQuitGap-1)) trans[i, i + 1] = 1
trans[lastWaitGap + nQuitGap, 1] = 1
# calculate the steady state
n = ncol(trans)
A = t(trans - diag(n))
A = rbind(A, rep(1, n))
b = c(rep(0, n), 1)
UHP = qr.solve(A, b)
rHP = c(unlist(lapply(1 : lastWaitGap, function(i) {
rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i: nGap])
})), rep(0, nQuitGap))
timeInGaps = c(unlist(lapply(1 : lastWaitGap, function(i) {
junk = rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])
junk * stepDuration + (1 - junk) * stepDuration
})), rep(iti / nQuitGap, nQuitGap))
meanTimePerAction = sum(UHP * timeInGaps)
Rt[lastWaitGap] = sum(UHP * rHP * 10) / meanTimePerAction
Rstep[lastWaitGap] = sum(UHP * rHP * 10)
}
Qwait
Rt
Rstep * gamma^0.1(1 - gamma ^ 0.1)
Rstep[200] * gamma^0.1 / (1 - gamma ^ 0.1)
meanTimePerAction
Rstep
Rstep[200] * gamma ^ stepDuration / (1 - gamma ^ stepDuration)
gammaPerStep = 0.90 # discount per 0.5s
gamma = gammaPerStep ^ 2
nGap = length(trialGapValues$HP)
nTick =  length(trialTicks$HP)
Qquit_ = vector(length = nGap)
Qwait_ = vector(mode = "list", length = nGap)
# t means quitting after t
for(quitGap in 1 : nGap){
quitAfter = stepDuration * quitGap
meanRewardDelay = getMeanRewardDelay(1, quitAfter, gammaPerStep)
rewardedDiscount = meanRewardDelay$discount * gamma ^ iti
meanWaitDelay = getMeanWaitDelay(1, quitAfter, gammaPerStep)
discount =  meanWaitDelay$discount * gamma ^ iti
pReward = getPreward(1, quitAfter, gammaPerStep)
Qquit =  pReward * tokenValue * rewardedDiscount / (1 - discount)
# Qquit =  sum(pReward * tokenValue * meanRewardDiscount * meanWaitDiscount ^ (0 : 10))
Qquit_[quitGap] = Qquit
Qwait = vector(length = quitGap)
for(j in 1 : quitGap){
meanRewardDelay = getMeanRewardDelay(j, quitAfter, gammaPerStep)
meanWaitDelay = getMeanWaitDelay(j, quitAfter, gammaPerStep)
rewardedDiscount = meanRewardDelay$discount
discount = meanWaitDelay$discount
pReward = getPreward(j, quitAfter, gammaPerStep)
Qwait[j] = tokenValue * rewardedDiscount * pReward + Qquit * discount
}
Qwait_[[quitGap]] = Qwait
}
nGap = length(trialGapValues$HP)
QHP = vector(length = length(nGap))
for(lastWaitGap in 1 : nGap){
# define the transition matrix
trans = matrix(rep(0, length = (lastWaitGap + nQuitGap)^2), nrow = lastWaitGap + nQuitGap)
if(lastWaitGap > 1) trans[1 : (lastWaitGap - 1), lastWaitGap + 1]  =
unlist(lapply(1:(lastWaitGap-1), function(i) rewardDelayPDF$HP[i] / sum(rewardDelayPDF$HP[i : nGap])))
trans[lastWaitGap, lastWaitGap + 1] = 1
if(lastWaitGap > 1) for(i in 1 : (lastWaitGap - 1)) trans[i, i+1] = 1 - trans[i, lastWaitGap + 1]
if(nQuitGap > 1) for(i in (lastWaitGap+1) : (lastWaitGap + nQuitGap-1)) trans[i, i + 1] = 1
trans[lastWaitGap + nQuitGap, 1] = 1
# calculate the steady state
n = ncol(trans)
A = t(trans - diag(n))
A = rbind(A, rep(1, n))
b = c(rep(0, n), 1)
UHP = qr.solve(A, b)
QquitList = Qquit_[[lastWaitGap]] * gamma ^ (-(0 : (nQuitGap - 1)) * stepDuration)
QHP[[lastWaitGap]] =  sum(UHP[1:lastWaitGap] * Qwait_[[lastWaitGap]]) + sum(UHP[lastWaitGap + (1 : nQuitGap)] * QquitList)
}
QHP[200]
