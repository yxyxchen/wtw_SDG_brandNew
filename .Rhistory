plotData$AUCRepSd = apply(AUCRep_, MARGIN = 1, FUN = sd)
plotData$AUCRepMin = plotData$AUCRep - plotData$AUCRepSd
plotData$AUCRepMax = plotData$AUCRep + plotData$AUCRepSd
AUCSummary = plotData
ggplot(plotData[plotData$id %in% useID, ],
aes(AUC, AUCRep)) +  geom_errorbar(aes(ymin = AUCRepMin, ymax = AUCRepMax), color = "grey")  + geom_point() + facet_grid(~condition) +
geom_abline(slope = 1, intercept = 0) + saveTheme + xlim(c(-2, 45)) + ylim(c(-2, 45)) +
ylab("Predicted AUC / min") + xlab("AUC / min")
fileName = sprintf("figures/expModelRepitation/AUC_AUCRep_%s.pdf", modelName)
ggsave(filename = fileName,  width = 6, height = 4)
# load model names
modelNames = c("reduce_one_phi", "reduce_one_gamma",
"reduce_one_QwaitIni", "reduce_two_QwaitIni",
"full_model")
nModel = length(modelNames)
nModel
# load experimental data
load("genData/expDataAnalysis/blockData.RData")
idList = unique(blockData$id)
n = length(idList)
# define a function for convinence
# select useID
useID_ = vector(mode = "list", length = nModel)
useID = idList
modelNames = c("baseline", "reduce_one_phi", "reduce_one_gamma",
"reduce_one_QwaitIni", "reduce_two_QwaitIni",
"full_model")
nModel = length(modelNames)
# load experimental data
load("genData/expDataAnalysis/blockData.RData")
idList = unique(blockData$id)
n = length(idList)
useID_ = vector(mode = "list", length = nModel)
useID = idList
source("subFxs/loadFxs.R")
for(i in 1 : nModel){
modelName = modelNames[i]
expPara = loadExpPara(modelName, getPars(modelName))
pars = getPars(modelName)
RhatCols = which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
EffeCols = which(str_detect(colnames(expPara), "Effe"))[1 : length(pars)]
useID_[[i]] = idList[apply(expPara[,RhatCols] < 1.1, MARGIN = 1, sum) == length(pars) &
apply(expPara[,EffeCols] >100, MARGIN = 1, sum) == length(pars)]
useID = idList[idList %in% useID_[[i]] & idList %in% useID]
}
nUse = length(useID)
# select useID
useID_ = vector(mode = "list", length = nModel)
useID = idList
source("subFxs/loadFxs.R")
for(i in 1 : nModel){
modelName = modelNames[i]
expPara = loadExpPara(modelName, getParas(modelName))
pars = getPars(modelName)
RhatCols = which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
EffeCols = which(str_detect(colnames(expPara), "Effe"))[1 : length(pars)]
useID_[[i]] = idList[apply(expPara[,RhatCols] < 1.1, MARGIN = 1, sum) == length(pars) &
apply(expPara[,EffeCols] >100, MARGIN = 1, sum) == length(pars)]
useID = idList[idList %in% useID_[[i]] & idList %in% useID]
}
nUse = length(useID)
# define a function for convinence
# select useID
useID_ = vector(mode = "list", length = nModel)
useID = idList
source("subFxs/loadFxs.R")
for(i in 1 : nModel){
modelName = modelNames[i]
expPara = loadExpPara(modelName, getParas(modelName))
pars = getParas(modelName)
RhatCols = which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
EffeCols = which(str_detect(colnames(expPara), "Effe"))[1 : length(pars)]
useID_[[i]] = idList[apply(expPara[,RhatCols] < 1.1, MARGIN = 1, sum) == length(pars) &
apply(expPara[,EffeCols] >100, MARGIN = 1, sum) == length(pars)]
useID = idList[idList %in% useID_[[i]] & idList %in% useID]
}
nUse = length(useID)
i
modelName = modelNames[i]
expPara = loadExpPara(modelName, getParas(modelName))
pars = getParas(modelName)
RhatCols = which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
EffeCols = which(str_detect(colnames(expPara), "Effe"))[1 : length(pars)]
useID_[[i]] = idList[apply(expPara[,RhatCols] < 1.1, MARGIN = 1, sum) == length(pars) &
apply(expPara[,EffeCols] >100, MARGIN = 1, sum) == length(pars)]
useID = idList[idList %in% useID_[[i]] & idList %in% useID]
idList[apply(expPara[,RhatCols] < 1.1, MARGIN = 1, sum) == length(pars) &
apply(expPara[,EffeCols] >100, MARGIN = 1, sum) == length(pars)]
expPara
loadExpPara(modelName, getParas(modelName))
View(expPara)
source('~/Documents/first_kick/wtw_SDG_brandNew/subFxs/helpFxs.R', echo=TRUE)
source('~/Documents/first_kick/wtw_SDG_brandNew/subFxs/helpFxs.R', echo=TRUE)
for(i in 1 : nModel){
modelName = modelNames[i]
expPara = loadExpPara(modelName, getParas(modelName))
pars = getParas(modelName)
RhatCols = which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
EffeCols = which(str_detect(colnames(expPara), "Effe"))[1 : length(pars)]
useID_[[i]] = idList[apply(expPara[,RhatCols] < 1.1, MARGIN = 1, sum) == length(pars) &
apply(expPara[,EffeCols] >100, MARGIN = 1, sum) == length(pars)]
useID = idList[idList %in% useID_[[i]] & idList %in% useID]
}
nUse = length(useID)
i
modelName = modelNames[i]
expPara = loadExpPara(modelName, getParas(modelName))
View(expPara)
RhatCols = which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
length(pars)
which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
RhatCols = which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
EffeCols = which(str_detect(colnames(expPara), "Effe"))[1 : length(pars)]
useID_[[i]] = idList[apply(expPara[,RhatCols] < 1.1, MARGIN = 1, sum) == length(pars) &
apply(expPara[,EffeCols] >100, MARGIN = 1, sum) == length(pars)]
which(str_detect(colnames(expPara), "Effe"))[1 : length(pars)]
for(i in 1 : nModel){
modelName = modelNames[i]
expPara = loadExpPara(modelName, getParas(modelName))
pars = getParas(modelName)
RhatCols = which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
EffeCols = which(str_detect(colnames(expPara), "Effe"))[1 : length(pars)]
if(length(pars) <= 1){
useID_[[i]]  = idList[expPara[,RhatCols]<1.1 & expPara[,EffeCols] > 100]
}else{
useID_[[i]] = idList[apply(expPara[,RhatCols] < 1.1, MARGIN = 1, sum) == length(pars) &
apply(expPara[,EffeCols] >100, MARGIN = 1, sum) == length(pars)]
}
useID = idList[idList %in% useID_[[i]] & idList %in% useID]
}
nUse = length(useID)
i
paras
source('~/Documents/first_kick/wtw_SDG_brandNew/subFxs/helpFxs.R', echo=TRUE)
for(i in 1 : nModel){
modelName = modelNames[i]
expPara = loadExpPara(modelName, getParas(modelName))
pars = getParas(modelName)
RhatCols = which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
EffeCols = which(str_detect(colnames(expPara), "Effe"))[1 : length(pars)]
if(length(pars) <= 1){
useID_[[i]]  = idList[expPara[,RhatCols]<1.1 & expPara[,EffeCols] > 100]
}else{
useID_[[i]] = idList[apply(expPara[,RhatCols] < 1.1, MARGIN = 1, sum) == length(pars) &
apply(expPara[,EffeCols] >100, MARGIN = 1, sum) == length(pars)]
}
useID = idList[idList %in% useID_[[i]] & idList %in% useID]
}
nUse = length(useID)
nUse
useID_[[i]]
i
useID_[[1]]
useID_[[2]]
useID_[[3]]
useID_[[4]]
useID_[[5]]
useID_[[6]]
useID_ = vector(mode = "list", length = nModel)
useID = idList
source("subFxs/loadFxs.R")
for(i in 1 : nModel){
modelName = modelNames[i]
expPara = loadExpPara(modelName, getParas(modelName))
pars = getParas(modelName)
RhatCols = which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
EffeCols = which(str_detect(colnames(expPara), "Effe"))[1 : length(pars)]
if(length(pars) <= 1){
useID_[[i]]  = idList[expPara[,RhatCols]<1.1 & expPara[,EffeCols] > 100]
}else{
useID_[[i]] = idList[apply(expPara[,RhatCols] < 1.1, MARGIN = 1, sum) == length(pars) &
apply(expPara[,EffeCols] >100, MARGIN = 1, sum) == length(pars)]
}
useID = idList[idList %in% useID_[[i]] & idList %in% useID]
}
nUse = length(useID)
nUSe
nUse
# since p_waic is very noise, therefore pay more attention to logLik_
logEvidence_ = matrix(NA, nUse, nModel)
logLik_ = matrix(NA, nUse, nModel)
logLikPerAct_ = matrix(NA, nUse, nModel)
logEvidencePerAct_ = matrix(NA, nUse, nModel) # save later for model comparison
pWaic_ = matrix(NA, nUse, nModel)
for(m in 1 : nModel){
modelName = modelNames[m]
for(sIdx in 1 : nUse ){
id = useID[sIdx]
nAction = blockData$nAction[blockData$id == id & blockData$blockNum == 1]
fileName = sprintf("genData/expModelFitting/%s/s%d_waic.RData", modelName, id)
load(fileName)
logEvidence_[sIdx, m] = WAIC$elpd_waic
logEvidencePerAct_[sIdx, m] = WAIC$elpd_waic/ nAction
pWaic_[sIdx, m] = WAIC$p_waic
paraSummary = read.csv(sprintf("genData/expModelFitting/%s/s%d_summary.txt", modelName, id), header = F)
logLik_[sIdx, m] = paraSummary[ nrow(paraSummary) - 1, 1]
}
}
mean(logEvidence_[,1]- logEvidence_[,6])
mean(logEvidence_[,2]- logEvidence_[,6])
mean(waic_[,1]- waic_[,6])
logEvidence_[,1]
waic_ = -2 * logEvidence_
logEvidence_[,1]
mean(waic_[,1]- waic_[,6])
mean(waic_[,2]- waic_[,6])
mean(waic_[,3]- waic_[,6])
mean(waic_[,4]- waic_[,6])
mean(waic_[,5]- waic_[,6])
f= "genData/expModelFitting/logEvidenceList.csv"
write.table(file = f, logEvidence_, sep = ",", col.names = F, row.names = F)
modelNames = c("baseline",
"full_model")
nModel = length(modelNames)
# load experimental data
load("genData/expDataAnalysis/blockData.RData")
idList = unique(blockData$id)
n = length(idList)
# define a function for convinence
# select useID
useID_ = vector(mode = "list", length = nModel)
useID = idList
source("subFxs/loadFxs.R")
for(i in 1 : nModel){
modelName = modelNames[i]
expPara = loadExpPara(modelName, getParas(modelName))
pars = getParas(modelName)
RhatCols = which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
EffeCols = which(str_detect(colnames(expPara), "Effe"))[1 : length(pars)]
if(length(pars) <= 1){
useID_[[i]]  = idList[expPara[,RhatCols]<1.1 & expPara[,EffeCols] > 100]
}else{
useID_[[i]] = idList[apply(expPara[,RhatCols] < 1.1, MARGIN = 1, sum) == length(pars) &
apply(expPara[,EffeCols] >100, MARGIN = 1, sum) == length(pars)]
}
useID = idList[idList %in% useID_[[i]] & idList %in% useID]
}
nUse = length(useID)
logEvidence_ = matrix(NA, nUse, nModel)
logLik_ = matrix(NA, nUse, nModel)
logLikPerAct_ = matrix(NA, nUse, nModel)
logEvidencePerAct_ = matrix(NA, nUse, nModel) # save later for model comparison
pWaic_ = matrix(NA, nUse, nModel)
for(m in 1 : nModel){
modelName = modelNames[m]
for(sIdx in 1 : nUse ){
id = useID[sIdx]
nAction = blockData$nAction[blockData$id == id & blockData$blockNum == 1]
fileName = sprintf("genData/expModelFitting/%s/s%d_waic.RData", modelName, id)
load(fileName)
logEvidence_[sIdx, m] = WAIC$elpd_waic
logEvidencePerAct_[sIdx, m] = WAIC$elpd_waic/ nAction
pWaic_[sIdx, m] = WAIC$p_waic
paraSummary = read.csv(sprintf("genData/expModelFitting/%s/s%d_summary.txt", modelName, id), header = F)
logLik_[sIdx, m] = paraSummary[ nrow(paraSummary) - 1, 1]
}
}
waic_ = -2 * logEvidence_
mean(waic_[,1] - waic_[,2])
nUse
f= "genData/expModelFitting/logEvidenceList.csv"
write.table(file = f, logEvidence_, sep = ",", col.names = F, row.names = F)
modelNames = c("baseline", "reduce_one_phi", "reduce_one_gamma",
"reduce_one_QwaitIni", "reduce_two_QwaitIni",
"full_model")
modelNames = c("reduce_one_phi",
"full_model")
nModel = length(modelNames)
# load experimental data
load("genData/expDataAnalysis/blockData.RData")
idList = unique(blockData$id)
n = length(idList)
# define a function for convinence
# select useID
useID_ = vector(mode = "list", length = nModel)
useID = idList
source("subFxs/loadFxs.R")
for(i in 1 : nModel){
modelName = modelNames[i]
expPara = loadExpPara(modelName, getParas(modelName))
pars = getParas(modelName)
RhatCols = which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
EffeCols = which(str_detect(colnames(expPara), "Effe"))[1 : length(pars)]
if(length(pars) <= 1){
useID_[[i]]  = idList[expPara[,RhatCols]<1.1 & expPara[,EffeCols] > 100]
}else{
useID_[[i]] = idList[apply(expPara[,RhatCols] < 1.1, MARGIN = 1, sum) == length(pars) &
apply(expPara[,EffeCols] >100, MARGIN = 1, sum) == length(pars)]
}
useID = idList[idList %in% useID_[[i]] & idList %in% useID]
}
nUse = length(useID)
# since p_waic is very noise, therefore pay more attention to logLik_
logEvidence_ = matrix(NA, nUse, nModel)
logLik_ = matrix(NA, nUse, nModel)
logLikPerAct_ = matrix(NA, nUse, nModel)
logEvidencePerAct_ = matrix(NA, nUse, nModel) # save later for model comparison
pWaic_ = matrix(NA, nUse, nModel)
for(m in 1 : nModel){
modelName = modelNames[m]
for(sIdx in 1 : nUse ){
id = useID[sIdx]
nAction = blockData$nAction[blockData$id == id & blockData$blockNum == 1]
fileName = sprintf("genData/expModelFitting/%s/s%d_waic.RData", modelName, id)
load(fileName)
logEvidence_[sIdx, m] = WAIC$elpd_waic
logEvidencePerAct_[sIdx, m] = WAIC$elpd_waic/ nAction
pWaic_[sIdx, m] = WAIC$p_waic
paraSummary = read.csv(sprintf("genData/expModelFitting/%s/s%d_summary.txt", modelName, id), header = F)
logLik_[sIdx, m] = paraSummary[ nrow(paraSummary) - 1, 1]
}
}
waic_ = -2 * logEvidence_
mean(waic_[,1] - waic_[,2])
f= "genData/expModelFitting/logEvidenceList.csv"
write.table(file = f, logEvidence_, sep = ",", col.names = F, row.names = F)
# load model names
modelNames = c("baseline", "reduce_one_phi", "reduce_one_gamma",
"reduce_one_QwaitIni", "reduce_two_QwaitIni",
"full_model")
modelNames = c("reduce_one_gamma",
"full_model")
nModel = length(modelNames)
# load experimental data
load("genData/expDataAnalysis/blockData.RData")
idList = unique(blockData$id)
n = length(idList)
# define a function for convinence
# select useID
useID_ = vector(mode = "list", length = nModel)
useID = idList
source("subFxs/loadFxs.R")
for(i in 1 : nModel){
modelName = modelNames[i]
expPara = loadExpPara(modelName, getParas(modelName))
pars = getParas(modelName)
RhatCols = which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
EffeCols = which(str_detect(colnames(expPara), "Effe"))[1 : length(pars)]
if(length(pars) <= 1){
useID_[[i]]  = idList[expPara[,RhatCols]<1.1 & expPara[,EffeCols] > 100]
}else{
useID_[[i]] = idList[apply(expPara[,RhatCols] < 1.1, MARGIN = 1, sum) == length(pars) &
apply(expPara[,EffeCols] >100, MARGIN = 1, sum) == length(pars)]
}
useID = idList[idList %in% useID_[[i]] & idList %in% useID]
}
nUse = length(useID)
logEvidence_ = matrix(NA, nUse, nModel)
logLik_ = matrix(NA, nUse, nModel)
logLikPerAct_ = matrix(NA, nUse, nModel)
logEvidencePerAct_ = matrix(NA, nUse, nModel) # save later for model comparison
pWaic_ = matrix(NA, nUse, nModel)
for(m in 1 : nModel){
modelName = modelNames[m]
for(sIdx in 1 : nUse ){
id = useID[sIdx]
nAction = blockData$nAction[blockData$id == id & blockData$blockNum == 1]
fileName = sprintf("genData/expModelFitting/%s/s%d_waic.RData", modelName, id)
load(fileName)
logEvidence_[sIdx, m] = WAIC$elpd_waic
logEvidencePerAct_[sIdx, m] = WAIC$elpd_waic/ nAction
pWaic_[sIdx, m] = WAIC$p_waic
paraSummary = read.csv(sprintf("genData/expModelFitting/%s/s%d_summary.txt", modelName, id), header = F)
logLik_[sIdx, m] = paraSummary[ nrow(paraSummary) - 1, 1]
}
}
waic_ = -2 * logEvidence_
mean(waic_[,1] - waic_[,2])
f= "genData/expModelFitting/logEvidenceList.csv"
write.table(file = f, logEvidence_, sep = ",", col.names = F, row.names = F)
# load model names
modelNames = c("baseline", "reduce_one_phi", "reduce_one_gamma",
"reduce_one_QwaitIni", "reduce_two_QwaitIni",
"full_model")
modelNames = c("reduce_one_QwaitIni",
"full_model")
nModel = length(modelNames)
# load experimental data
load("genData/expDataAnalysis/blockData.RData")
idList = unique(blockData$id)
n = length(idList)
# define a function for convinence
# select useID
useID_ = vector(mode = "list", length = nModel)
useID = idList
source("subFxs/loadFxs.R")
for(i in 1 : nModel){
modelName = modelNames[i]
expPara = loadExpPara(modelName, getParas(modelName))
pars = getParas(modelName)
RhatCols = which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
EffeCols = which(str_detect(colnames(expPara), "Effe"))[1 : length(pars)]
if(length(pars) <= 1){
useID_[[i]]  = idList[expPara[,RhatCols]<1.1 & expPara[,EffeCols] > 100]
}else{
useID_[[i]] = idList[apply(expPara[,RhatCols] < 1.1, MARGIN = 1, sum) == length(pars) &
apply(expPara[,EffeCols] >100, MARGIN = 1, sum) == length(pars)]
}
useID = idList[idList %in% useID_[[i]] & idList %in% useID]
}
nUse = length(useID)
# extract logEvidence per trial
# here logEvidence is on the loglikelyhood scale, so it is negtive
# also, it accounts for model complexity
# logLik_ doesn't account for model complexity
# since p_waic is very noise, therefore pay more attention to logLik_
logEvidence_ = matrix(NA, nUse, nModel)
logLik_ = matrix(NA, nUse, nModel)
logLikPerAct_ = matrix(NA, nUse, nModel)
logEvidencePerAct_ = matrix(NA, nUse, nModel) # save later for model comparison
pWaic_ = matrix(NA, nUse, nModel)
for(m in 1 : nModel){
modelName = modelNames[m]
for(sIdx in 1 : nUse ){
id = useID[sIdx]
nAction = blockData$nAction[blockData$id == id & blockData$blockNum == 1]
fileName = sprintf("genData/expModelFitting/%s/s%d_waic.RData", modelName, id)
load(fileName)
logEvidence_[sIdx, m] = WAIC$elpd_waic
logEvidencePerAct_[sIdx, m] = WAIC$elpd_waic/ nAction
pWaic_[sIdx, m] = WAIC$p_waic
paraSummary = read.csv(sprintf("genData/expModelFitting/%s/s%d_summary.txt", modelName, id), header = F)
logLik_[sIdx, m] = paraSummary[ nrow(paraSummary) - 1, 1]
}
}
waic_ = -2 * logEvidence_
mean(waic_[,1] - waic_[,2])
f= "genData/expModelFitting/logEvidenceList.csv"
write.table(file = f, logEvidence_, sep = ",", col.names = F, row.names = F)
modelName
modelNames = c("reduce_two_QwaitIni",
"full_model")
nModel = length(modelNames)
# load experimental data
load("genData/expDataAnalysis/blockData.RData")
idList = unique(blockData$id)
n = length(idList)
# define a function for convinence
# select useID
useID_ = vector(mode = "list", length = nModel)
useID = idList
source("subFxs/loadFxs.R")
for(i in 1 : nModel){
modelName = modelNames[i]
expPara = loadExpPara(modelName, getParas(modelName))
pars = getParas(modelName)
RhatCols = which(str_detect(colnames(expPara), "hat"))[1 : length(pars)]
EffeCols = which(str_detect(colnames(expPara), "Effe"))[1 : length(pars)]
if(length(pars) <= 1){
useID_[[i]]  = idList[expPara[,RhatCols]<1.1 & expPara[,EffeCols] > 100]
}else{
useID_[[i]] = idList[apply(expPara[,RhatCols] < 1.1, MARGIN = 1, sum) == length(pars) &
apply(expPara[,EffeCols] >100, MARGIN = 1, sum) == length(pars)]
}
useID = idList[idList %in% useID_[[i]] & idList %in% useID]
}
nUse = length(useID)
logEvidence_ = matrix(NA, nUse, nModel)
logLik_ = matrix(NA, nUse, nModel)
logLikPerAct_ = matrix(NA, nUse, nModel)
logEvidencePerAct_ = matrix(NA, nUse, nModel) # save later for model comparison
pWaic_ = matrix(NA, nUse, nModel)
for(m in 1 : nModel){
modelName = modelNames[m]
for(sIdx in 1 : nUse ){
id = useID[sIdx]
nAction = blockData$nAction[blockData$id == id & blockData$blockNum == 1]
fileName = sprintf("genData/expModelFitting/%s/s%d_waic.RData", modelName, id)
load(fileName)
logEvidence_[sIdx, m] = WAIC$elpd_waic
logEvidencePerAct_[sIdx, m] = WAIC$elpd_waic/ nAction
pWaic_[sIdx, m] = WAIC$p_waic
paraSummary = read.csv(sprintf("genData/expModelFitting/%s/s%d_summary.txt", modelName, id), header = F)
logLik_[sIdx, m] = paraSummary[ nrow(paraSummary) - 1, 1]
}
}
waic_ = -2 * logEvidence_
mean(waic_[,1] - waic_[,2])
f= "genData/expModelFitting/logEvidenceList.csv"
write.table(file = f, logEvidence_, sep = ",", col.names = F, row.names = F)
modelName = "full_model"
paras = getParas(modelName )
load(sprintf("genData/simulation/%s/simParas.RData", modelName))
c = 1
cond = conditions[c]
condColor = conditionColors[c]
simPara = loadSimPara(modelName, paras, cond)
colnames(paraComb) = paste0("real", paras)
nPara = length(paras)
dim(simPara)
rm(list = ls())
modelName = "full_model"
paras =c("phi", "tau", "gamma", "QwaitIni")
cond = "HP"
nE = length(paras) + 2
load(sprintf("genData/simulation/%s/simParas.RData", modelName))
n = nComb
nE = length(paras)
expPara = array(NA, dim = c(nComb, nRep, nE))
for(i in 1 : n){
expPara_ = matrix(NA, nRep, nE)
for(r in 1 : nRep){
fileName = sprintf("genData/simModelFitting/%s/%s_s%d_r%d_summary.txt",
modelName, cond, i, r)
junk = read.csv(fileName, header = F)
expPara_[r, ] = junk[,1]
}
expPara[i, , ] = expPara_
}
nE = length(paras) + 2
load(sprintf("genData/simulation/%s/simParas.RData", modelName))
